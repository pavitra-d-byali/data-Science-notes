{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa32ffe",
   "metadata": {},
   "source": [
    "# Random Forest: Classification and Regression\n",
    "\n",
    "In this video, we discuss the **Random Forest** machine learning algorithm for both **classification** and **regression** problems.\n",
    "\n",
    "Random Forest is an example of a **bagging ensemble technique**, where the base learners are specifically **decision trees**.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset and Notation\n",
    "\n",
    "- Dataset size: \\(d\\)  \n",
    "- Number of features: \\(m\\)  \n",
    "- Features: \\(f_1, f_2, \\dots, f_m\\)\n",
    "\n",
    "We denote the dataset as:\n",
    "\n",
    "\\[\n",
    "D = \\{(x_1, y_1), (x_2, y_2), \\dots, (x_d, y_d)\\}\n",
    "\\]\n",
    "\n",
    "where \\(x_i\\) represents feature vectors and \\(y_i\\) represents the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "## Base Learners\n",
    "\n",
    "- In Random Forest, all base learners are **decision trees**:\n",
    "\n",
    "\\[\n",
    "\\text{Decision Trees: } \\text{DT}_1, \\text{DT}_2, \\dots, \\text{DT}_N\n",
    "\\]\n",
    "\n",
    "- These trees are trained independently using different **samples of the dataset**.\n",
    "\n",
    "---\n",
    "\n",
    "## Sampling in Random Forest\n",
    "\n",
    "Random Forest uses **row sampling** and **feature sampling**:\n",
    "\n",
    "### Row Sampling\n",
    "\n",
    "- Randomly pick a subset of rows from the dataset.  \n",
    "- Denote sampled rows as \\(D'\\) (\\(|D'| < |D|\\)).  \n",
    "- **Sampling with replacement** is used (bootstrap sampling).\n",
    "\n",
    "### Feature Sampling\n",
    "\n",
    "- Randomly pick a subset of features for each decision tree.\n",
    "- Denote sampled features as \\(F'\\subseteq \\{f_1, f_2, \\dots, f_m\\}\\).\n",
    "\n",
    "\\[\n",
    "\\text{Training } \\text{DT}_i \\text{ on } (D'_i, F'_i)\n",
    "\\]\n",
    "\n",
    "- Each tree receives a **different subset of rows and features**, ensuring diversity.\n",
    "\n",
    "---\n",
    "\n",
    "## Training and Prediction\n",
    "\n",
    "### Classification\n",
    "\n",
    "1. Train each decision tree on its sampled dataset.  \n",
    "2. For a new test instance, each tree predicts a class.  \n",
    "3. Final output is obtained using **majority voting**:\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\text{mode}\\{\\text{DT}_1(x), \\text{DT}_2(x), \\dots, \\text{DT}_N(x)\\}\n",
    "\\]\n",
    "\n",
    "### Regression\n",
    "\n",
    "1. Train each decision tree on its sampled dataset.  \n",
    "2. For a new test instance, each tree predicts a continuous value.  \n",
    "3. Final output is the **average** of all tree predictions:\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{DT}_i(x)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## Why Use Random Forest Instead of a Single Decision Tree?\n",
    "\n",
    "### Decision Tree Problems\n",
    "\n",
    "- High likelihood of **overfitting** if tree is grown fully.  \n",
    "- Overfitting results in:\n",
    "  - High **training accuracy** (low bias)\n",
    "  - Low **test accuracy** (high variance)\n",
    "\n",
    "### Random Forest Advantages\n",
    "\n",
    "- Multiple trees trained on different subsets of data reduce **variance**.  \n",
    "- Majority voting or averaging across many trees increases **test accuracy**.  \n",
    "- Each tree becomes an **expert on a subset of data and features**, creating a **robust generalized model**.  \n",
    "- New records added to the dataset have minimal impact, as the effect is distributed across multiple trees.\n",
    "\n",
    "**Goal:** Achieve **low bias and low variance**.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- Random Forest is a **bagging-based ensemble** using **decision trees** as base learners.  \n",
    "- Uses **row and feature sampling with replacement** to train multiple trees.  \n",
    "- Predictions:\n",
    "  - **Classification:** Majority voting\n",
    "  - **Regression:** Average of predictions  \n",
    "- Reduces variance compared to a single decision tree and improves overall accuracy.  \n",
    "\n",
    "---\n",
    "\n",
    "Next, we will explore **boosting techniques** and see how they differ from bagging.\n",
    "\n",
    "---\n",
    "\n",
    "Thank you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28ee61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
