{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc3cc66",
   "metadata": {},
   "source": [
    "#  Difference between AI, ML, DL, and Data Science\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Artificial Intelligence (AI)\n",
    "**Definition:** AI is the broad field of creating systems or applications that can perform tasks without human intervention.  \n",
    "\n",
    "**Goal:** Make machines act intelligently and automate decision-making.  \n",
    "\n",
    "**Examples:**\n",
    "- Netflix Recommendation System – recommends movies/shows based on user viewing history.  \n",
    "- Self-Driving Cars – detect traffic lights, obstacles, pedestrians, and drive autonomously.  \n",
    "- Amazon Recommendations – suggests products based on user browsing and purchase history.  \n",
    "\n",
    " **AI = The Universe (the broadest concept).**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Machine Learning (ML)\n",
    "- **Subset of AI**  \n",
    "- **Definition:** ML provides statistical tools and algorithms to analyze data, learn patterns, and make predictions/forecasts.  \n",
    "- **Goal:** Train models to improve performance with data, without explicit programming.  \n",
    "\n",
    "**Applications:**  \n",
    "- Predictive analytics  \n",
    "- Fraud detection  \n",
    "- Demand forecasting  \n",
    "- Recommendation engines  \n",
    "\n",
    " **ML = A subset (circle inside AI).**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Deep Learning (DL)\n",
    "- **Subset of ML**  \n",
    "- **Definition:** Uses multi-layered neural networks to mimic how the human brain learns.  \n",
    "- **Origin:** Conceptualized in the 1950s – inspired by how humans learn from experiences.  \n",
    "- **Goal:** Learn complex patterns and representations from data.  \n",
    "\n",
    "**Key Technology:**  \n",
    "- Artificial Neural Networks (ANNs), especially Deep Neural Networks (DNNs).  \n",
    "\n",
    "**Applications:**  \n",
    "- Image recognition (e.g., detecting objects in photos).  \n",
    "- Speech recognition (e.g., Siri, Alexa).  \n",
    "- Natural Language Processing (e.g., ChatGPT, Google Translate).  \n",
    "\n",
    " **DL = A subset (circle inside ML).**\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Data Science\n",
    "- **Overlaps AI, ML, and DL**  \n",
    "- **Definition:** An interdisciplinary field that uses statistics, mathematics, programming, and domain knowledge to extract insights and build intelligent systems.  \n",
    "- **Goal:** Work with data end-to-end – from collection, cleaning, and analysis to building ML/DL models and deploying AI applications.  \n",
    "\n",
    "**Responsibilities of a Data Scientist:**  \n",
    "- Data preprocessing (EDA, feature engineering).  \n",
    "- Applying ML/DL techniques.  \n",
    "- Using statistics and linear algebra for analysis.  \n",
    "- Building AI-powered applications.  \n",
    "\n",
    "**Why overlapping?**  \n",
    "- Data Scientists may work on ML projects, DL projects, or general AI projects.  \n",
    "- They also use other tools like SQL, visualization, probability, and business analysis.  \n",
    "\n",
    " **Data Science = Overlapping all circles (AI, ML, DL + stats + domain expertise).**\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Key Hierarchy (Visualization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86beb8",
   "metadata": {},
   "source": [
    "AI (Universe)\n",
    "└── ML (Subset of AI)\n",
    "└── DL (Subset of ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fd475",
   "metadata": {},
   "source": [
    "#  Types of Machine Learning Techniques\n",
    "\n",
    "Machine Learning (ML) is generally divided into three main techniques:\n",
    "\n",
    "1. **Supervised Learning**  \n",
    "2. **Unsupervised Learning**  \n",
    "3. **Reinforcement Learning**  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Supervised Learning\n",
    "**Definition:** Learning with **labeled data**, i.e., the dataset has input features (independent variables) and a known output feature (dependent variable).  \n",
    "\n",
    "**Goal:** Train the model to map **inputs → output** so it can predict for new, unseen inputs.  \n",
    "\n",
    "**Example – House Price Prediction:**  \n",
    "- Features (independent): size of house, number of rooms.  \n",
    "- Output (dependent): price of house.  \n",
    "- Model learns relationship between features and output, then predicts price for new data.  \n",
    "\n",
    "**Key Characteristics:**  \n",
    "- Dataset has both input features and labeled output.  \n",
    "- Dependent feature (label) is **mandatory**.  \n",
    "\n",
    "**Types of Problems:**  \n",
    "- **Regression:** Output is continuous.  \n",
    "  - Example: Predicting house prices, predicting salary.  \n",
    "- **Classification:** Output is categorical.  \n",
    "  - Example: Predicting whether a student Pass/Fail.  \n",
    "  - **Binary Classification** → two categories (Yes/No, Pass/Fail).  \n",
    "  - **Multi-class Classification** → more than two categories.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Unsupervised Learning\n",
    "**Definition:** Learning with **unlabeled data**, i.e., dataset has only input features (no output labels).  \n",
    "\n",
    "**Goal:** Discover **patterns, structures, or groups (clusters)** in the data.  \n",
    "\n",
    "**Example – Customer Segmentation:**  \n",
    "- Features: salary, spending score.  \n",
    "- Task: Group customers into clusters based on similarity (e.g., high salary–high spenders, low salary–low spenders).  \n",
    "- Useful for targeted marketing, product recommendations, etc.  \n",
    "\n",
    "**Key Characteristics:**  \n",
    "- No labeled output feature.  \n",
    "- Focus on clustering or dimensionality reduction.  \n",
    "\n",
    "**Common Algorithms:**  \n",
    "- K-Means Clustering  \n",
    "- Hierarchical Clustering  \n",
    "- DBSCAN (Density-Based Clustering)  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Reinforcement Learning (RL)\n",
    "**Definition:** Learning by **interacting with an environment**, where an agent learns by trial and error using **rewards and penalties**.  \n",
    "\n",
    "**Goal:** Learn an **optimal sequence of actions** that maximize cumulative reward.  \n",
    "\n",
    "**Example:**  \n",
    "- A baby learning to walk: falls (penalty), walks a few steps (reward).  \n",
    "- Games: An AI agent playing chess or Atari learns moves based on win/loss rewards.  \n",
    "\n",
    "**Key Characteristics:**  \n",
    "- No fixed dataset.  \n",
    "- Learning happens through **feedback from the environment**.  \n",
    "\n",
    "**Components:**  \n",
    "- **Agent:** Learner/decision-maker.  \n",
    "- **Environment:** Where the agent acts.  \n",
    "- **Action:** What the agent does.  \n",
    "- **Reward:** Feedback (positive/negative).  \n",
    "\n",
    "---\n",
    "\n",
    "##  Algorithms Overview\n",
    "\n",
    "###  Supervised Learning\n",
    "**Regression:**\n",
    "- Linear Regression  \n",
    "- Ridge Regression  \n",
    "- Lasso Regression  \n",
    "- Elastic Net  \n",
    "\n",
    "**Classification:**\n",
    "- Logistic Regression  \n",
    "- Decision Tree  \n",
    "- Random Forest  \n",
    "- AdaBoost  \n",
    "- XGBoost, CatBoost (Boosting algorithms)  \n",
    "\n",
    "> Note: Some algorithms (e.g., Decision Trees, Random Forest, XGBoost) can handle both **regression and classification**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Unsupervised Learning\n",
    "- K-Means Clustering  \n",
    "- Hierarchical Clustering  \n",
    "- DBSCAN  \n",
    "\n",
    "---\n",
    "\n",
    "###  Reinforcement Learning\n",
    "- Q-Learning  \n",
    "- Deep Q-Networks (DQN)  \n",
    "- Policy Gradient Methods  \n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Supervised Learning:** Uses **labeled data** → Prediction (Regression/Classification).  \n",
    "- **Unsupervised Learning:** Uses **unlabeled data** → Pattern Discovery (Clustering).  \n",
    "- **Reinforcement Learning:** Learns by **interacting with the environment** → Decision-Making via Rewards.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de39a9",
   "metadata": {},
   "source": [
    "# Equation of a Straight Line (2D)\n",
    "\n",
    "### General form\n",
    "\n",
    "[\n",
    "y = mx + c\n",
    "]\n",
    "\n",
    "* **m** → slope → change in (y) for unit change in (x)\n",
    "* **c** → intercept → point where the line cuts the y-axis (when (x=0))\n",
    "\n",
    "---\n",
    "\n",
    "### Alternate notations\n",
    "\n",
    "* \n",
    "  y=β0​+β1​x\n",
    "  [\n",
    "  ax + by + c = 0\n",
    "  ]\n",
    "\n",
    "---\n",
    "\n",
    "### Converting (ax + by + c = 0) into slope-intercept form\n",
    "\n",
    "[\n",
    "y=−a/b​x−c/b​\n",
    "]\n",
    "\n",
    "\n",
    "* Slope: (m = -\\frac{a}{b})\n",
    "* Intercept: (c = -\\frac{c}{b})\n",
    "\n",
    "---\n",
    "\n",
    "# Straight Line in Higher Dimensions\n",
    "\n",
    "For 2 variables ((x_1, x_2)):\n",
    "\n",
    "[\n",
    "w_1 x_1 + w_2 x_2 + b = 0\n",
    "]\n",
    "\n",
    "**Vector form**:\n",
    "[\n",
    "w^T x + b = 0\n",
    "]\n",
    "\n",
    "Where:\n",
    "\n",
    "* (w = \\begin{bmatrix} w_1 \\ w_2 \\end{bmatrix})\n",
    "* (x = \\begin{bmatrix} x_1 \\ x_2 \\end{bmatrix})\n",
    "\n",
    "If the line passes through the origin:\n",
    "[\n",
    "w^T x = 0\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "# Plane in 3D\n",
    "\n",
    "Equation:\n",
    "[\n",
    "w_1 x_1 + w_2 x_2 + w_3 x_3 + b = 0\n",
    "]\n",
    "\n",
    "**Vector form**:\n",
    "[\n",
    "w^T x + b = 0\n",
    "]\n",
    "\n",
    "Where:\n",
    "\n",
    "* (w = \\begin{bmatrix} w_1 \\ w_2 \\ w_3 \\end{bmatrix})\n",
    "* (x = \\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\end{bmatrix})\n",
    "\n",
    "**Geometric meaning**:\n",
    "\n",
    "* (w) is perpendicular (normal vector) to the plane.\n",
    "* If (b=0), the plane passes through the origin.\n",
    "\n",
    "---\n",
    "\n",
    "# Hyperplane (n-Dimensions)\n",
    "\n",
    "General form:\n",
    "[\n",
    "w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b = 0\n",
    "]\n",
    "\n",
    "**Vector form**:\n",
    "[\n",
    "w^T x + b = 0\n",
    "]\n",
    "\n",
    "Where:\n",
    "\n",
    "* (w = (w_1, w_2, \\dots, w_n)) → weight/coefficients\n",
    "* (x = (x_1, x_2, \\dots, x_n)) → input vector\n",
    "* (b) → intercept\n",
    "\n",
    "---\n",
    "\n",
    "# Linear Algebra Connection\n",
    "\n",
    "**Dot product**:\n",
    "[\n",
    "w^T x = |w||x|\\cos\\theta\n",
    "]\n",
    "\n",
    "* If (w^T x = 0), then (\\cos\\theta = 0 \\Rightarrow \\theta = 90^\\circ).\n",
    "* This means (w) is perpendicular to (x) lying on the hyperplane.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "* **2D line**:\n",
    "  [\n",
    "  y = mx + c \\quad \\text{or} \\quad w^T x + b = 0\n",
    "  ]\n",
    "\n",
    "* **3D plane**:\n",
    "  [\n",
    "  w_1 x_1 + w_2 x_2 + w_3 x_3 + b = 0\n",
    "  ]\n",
    "\n",
    "* **nD hyperplane**:\n",
    "  [\n",
    "  w^T x + b = 0\n",
    "  ]\n",
    "\n",
    "**Key points**:\n",
    "\n",
    "* (w) = weight vector → normal (perpendicular) to line/plane/hyperplane\n",
    "* (b) = intercept → controls shift from origin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f6854",
   "metadata": {},
   "source": [
    "# Distance of a Point from a Plane\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Equation of a Plane\n",
    "\n",
    "* Consider a plane denoted by **π**.\n",
    "* If the plane passes through the origin, its equation can be written as:\n",
    "\n",
    "[\n",
    "w^T x = 0\n",
    "]\n",
    "\n",
    "where:\n",
    "\n",
    "* ( w ) = normal vector (perpendicular to the plane)\n",
    "* ( x ) = any point on the plane\n",
    "\n",
    "Thus, **( w )** is perpendicular to the plane.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Distance of a Point from a Plane\n",
    "\n",
    "Suppose we have a point:\n",
    "\n",
    "[\n",
    "s = (x_1, x_2, x_3, \\dots, x_n)\n",
    "]\n",
    "\n",
    "in an ( n )-dimensional space.\n",
    "\n",
    "The distance ( d ) of this point from the plane is given by:\n",
    "\n",
    "[\n",
    "d = \\frac{w^T s}{|w|}\n",
    "]\n",
    "\n",
    "where:\n",
    "\n",
    "* ( w^T s ) = dot product of ( w ) and ( s )\n",
    "* ( |w| ) = magnitude of ( w )\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Understanding the Formula\n",
    "\n",
    "From dot product definition:\n",
    "\n",
    "[\n",
    "w^T s = |w| \\cdot |s| \\cdot \\cos \\theta\n",
    "]\n",
    "\n",
    "where ( \\theta ) is the angle between ( w ) and ( s ).\n",
    "\n",
    "* If ( 0^\\circ \\leq \\theta < 90^\\circ ), then ( \\cos \\theta > 0 ) ⇒ **distance is positive**.\n",
    "* If ( 90^\\circ < \\theta < 270^\\circ ), then ( \\cos \\theta < 0 ) ⇒ **distance is negative**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Interpretation\n",
    "\n",
    "* **Above the plane (same direction as ( w ))**\n",
    "  [\n",
    "  d > 0\n",
    "  ]\n",
    "  Distance is positive.\n",
    "\n",
    "* **Below the plane (opposite to ( w ))**\n",
    "  [\n",
    "  d < 0\n",
    "  ]\n",
    "  Distance is negative.\n",
    "  (Here \"negative\" does not mean negative distance literally, but indicates the point lies on the **opposite side** of the plane relative to ( w ).)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Application in Machine Learning\n",
    "\n",
    "* In **Logistic Regression**:\n",
    "  Helps classify points by checking which side of the plane (decision boundary) they lie on.\n",
    "\n",
    "* In **SVM (Support Vector Machine)**:\n",
    "  The concept of distance from a hyperplane is central in finding the **maximum margin classifier**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Key Points\n",
    "\n",
    "1. Equation of plane: ( w^T x = 0 ).\n",
    "2. Distance formula:\n",
    "   [\n",
    "   d = \\frac{w^T s}{|w|}\n",
    "   ]\n",
    "3. Distance is **positive** above the plane, **negative** below the plane.\n",
    "4. Negative distance only means the point lies in the **opposite half-space** of the plane.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45079adc",
   "metadata": {},
   "source": [
    "# Instance-Based Learning vs Model-Based Learning\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Key Concept\n",
    "\n",
    "Machine learning models can learn in **two primary ways**:\n",
    "\n",
    "1. **Instance-Based Learning**:\n",
    "\n",
    "   * Learns directly from **training data**.\n",
    "   * For every prediction, it **depends on existing instances**.\n",
    "   * No explicit pattern or model is created.\n",
    "   * Analogous to **memorizing data**.\n",
    "\n",
    "2. **Model-Based Learning**:\n",
    "\n",
    "   * Learns the **pattern** in the training data.\n",
    "   * Creates a **generalized model** for future predictions.\n",
    "   * Can predict unseen data efficiently.\n",
    "   * Analogous to **understanding the concept**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Example: Predicting Student Pass/Fail\n",
    "\n",
    "Features:\n",
    "\n",
    "* `Play hours`\n",
    "* `Study hours`\n",
    "* Target: `Pass/Fail`\n",
    "\n",
    "### Instance-Based Learning\n",
    "\n",
    "* Looks at the **training data around the new query point**.\n",
    "* Decision depends on **neighboring points**.\n",
    "* Example: K-Nearest Neighbors (KNN)\n",
    "* Acts like a **domain expert**:\n",
    "\n",
    "  * New point surrounded by \"Fail\" → predicts **Fail**\n",
    "  * New point surrounded by \"Pass\" → predicts **Pass**\n",
    "* Does **not learn patterns**, just memorizes data.\n",
    "\n",
    "### Model-Based Learning\n",
    "\n",
    "* Learns the **pattern** in the data.\n",
    "* Creates a **decision boundary** or curve (decision function).\n",
    "* Can predict **new/unseen data** using the learned pattern.\n",
    "* Generalizes well beyond current training data.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Differences Between Instance-Based and Model-Based Learning\n",
    "\n",
    "| Aspect                    | Model-Based Learning                                   | Instance-Based Learning                                   |\n",
    "| ------------------------- | ------------------------------------------------------ | --------------------------------------------------------- |\n",
    "| **Training Data**         | Required to train the model                            | Required for predictions                                  |\n",
    "| **Pattern Discovery**     | During training, discovers patterns & generalizes      | No pattern discovery; prediction depends on neighbors     |\n",
    "| **Model Storage**         | Stored as serialized model (pickle, HDF5, etc.)        | Requires storing entire training data                     |\n",
    "| **Generalization**        | Yes, can predict unseen instances                      | No, depends on training data                              |\n",
    "| **Scoring New Instances** | Fast, uses mathematical equations in model             | Slower, computes distance to neighbors                    |\n",
    "| **Storage Requirement**   | Less (model file size small)                           | More (entire dataset must be stored)                      |\n",
    "| **Approach**              | Generalizing                                           | Memorizing                                                |\n",
    "| **Example Algorithms**    | Linear Regression, Logistic Regression, Decision Trees | K-Nearest Neighbors, Memory-Based Collaborative Filtering |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Summary\n",
    "\n",
    "* **Instance-Based Learning** = Memorize & use training data directly\n",
    "* **Model-Based Learning** = Learn patterns & generalize for future data\n",
    "\n",
    "**Key Point:**\n",
    "Generalizing (model-based learning) is usually **better** than memorizing (instance-based learning), but some use cases may still require instance-based approaches.\n",
    "\n",
    "---\n",
    "\n",
    "✅ Understanding this difference is critical for choosing the right approach for **classification, regression, or other ML tasks**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77e288",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
