{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12f475d",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) – Mathematical Intuition\n",
    "\n",
    "Unlike classification, in regression the output $$ y $$ is **continuous**.\n",
    "The goal of SVR is to find a **best-fit line (or hyperplane)** such that most data points lie within a margin of tolerance.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. SVR Hyperplane and Margins\n",
    "\n",
    "* Best-fit line:\n",
    "  $$\n",
    "  f(x) = w^T x + b\n",
    "  $$\n",
    "\n",
    "* Margins:\n",
    "  $$\n",
    "  f(x) + \\epsilon \\quad \\text{and} \\quad f(x) - \\epsilon\n",
    "  $$\n",
    "\n",
    "Here, $$ \\epsilon $$ is the **margin of tolerance** (maximum allowed error).\n",
    "Most points should lie within this “epsilon tube.”\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Constraints\n",
    "\n",
    "For each data point $$ (x_i, y_i) $$:\n",
    "\n",
    "$$\n",
    "|y_i - (w^T x_i + b)| \\leq \\epsilon\n",
    "$$\n",
    "\n",
    "If the point lies inside the margin → no penalty.\n",
    "If it lies outside → introduce slack variables $$ \\xi_i, \\xi_i^* \\geq 0 $$:\n",
    "\n",
    "* Above the tube: $$ y_i - (w^T x_i + b) > \\epsilon + \\xi_i $$\n",
    "* Below the tube: $$ (w^T x_i + b) - y_i > \\epsilon + \\xi_i^* $$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. SVR Cost Function\n",
    "\n",
    "The optimization problem is:\n",
    "\n",
    "$$\n",
    "\\min_{w, b, \\xi, \\xi^*} \\ \\frac{1}{2} | w |^2 + C \\sum_{i=1}^{n} (\\xi_i + \\xi_i^*)\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_i - (w^T x_i + b) &\\leq \\epsilon + \\xi_i \\\n",
    "(w^T x_i + b) - y_i &\\leq \\epsilon + \\xi_i^* \\\n",
    "\\xi_i, \\ \\xi_i^* &\\geq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Parameters Recap\n",
    "\n",
    "*  w  → weight vector (defines hyperplane)\n",
    "*  b  → bias\n",
    "*  epsilon  → margin of tolerance (insensitive loss)\n",
    "*  \\xi_i, \\xi_i^*  → slack variables (deviation outside margin)\n",
    "*  C  → regularization (trade-off between flatness of hyperplane and error penalty)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Key Idea\n",
    "\n",
    "* **Inside margin ($\\epsilon$-tube):** no penalty\n",
    "* **Outside margin:** penalty proportional to deviation\n",
    "* SVR balances **flatness of function** with **tolerance to small errors**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2bcc15",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) – Complete Notes\n",
    "\n",
    "In this video, we are going to discuss the **Support Vector Regression (SVR)** machine learning algorithm.\n",
    "\n",
    "In our previous video, we have already seen **Support Vector Classifier (SVC)** and we have learned:\n",
    "\n",
    "- What is the cost function  \n",
    "- What are the constraints  \n",
    "- About a new loss function called **hinge loss**  \n",
    "\n",
    "In this hinge loss, we have two parameters:  \n",
    "- $$ C_i $$  \n",
    "- $$ \\epsilon $$  \n",
    "\n",
    "Our main aim is to reduce this cost function by changing $$ w $$ and $$ b $$.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Regression Problem Statement\n",
    "\n",
    "For a regression problem:\n",
    "\n",
    "1. We need to find a **best-fit line**.  \n",
    "2. We need to find **marginal planes**.  \n",
    "3. We have to ensure that the distance between these planes is maximum.  \n",
    "\n",
    "### Example:\n",
    "\n",
    "- **Y-axis:** Price of a house  \n",
    "- **X-axis:** Size of the house  \n",
    "- Goal: Predict the price of the house based on its size using SVR.\n",
    "\n",
    "> This is a **regression problem** because the output $$ y $$ is a **continuous value**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. SVR Best-Fit Line and Margins\n",
    "\n",
    "The best-fit line can be represented as:\n",
    "\n",
    "$$\n",
    "f(x) = w^T x + b\n",
    "$$\n",
    "\n",
    "- **Top marginal plane:**  \n",
    "  $$\n",
    "  w^T x + b + \\epsilon\n",
    "  $$\n",
    "- **Bottom marginal plane:**  \n",
    "  $$\n",
    "  w^T x + b - \\epsilon\n",
    "  $$\n",
    "\n",
    "Here, $$ \\epsilon $$ is the **margin error**, i.e., the distance from the best-fit line to the top/bottom marginal plane.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. SVR Constraints\n",
    "\n",
    "- Most points should lie **within the margin**:  \n",
    "\n",
    "$$\n",
    "|y_i - (w^T x_i + b)| \\leq \\epsilon\n",
    "$$\n",
    "\n",
    "- If a point lies **inside the margin**, no penalty is applied.  \n",
    "- If a point lies **outside the margin**, define **deviations** as slack variables:\n",
    "\n",
    "  - Above the top margin:  \n",
    "    $$\n",
    "    y_i - (w^T x_i + b) > \\epsilon \\implies \\eta_i\n",
    "    $$\n",
    "\n",
    "  - Below the bottom margin:  \n",
    "    $$\n",
    "    (w^T x_i + b) - y_i > \\epsilon \\implies \\eta_i\n",
    "    $$\n",
    "\n",
    "Here, $$ \\eta_i $$ is the **distance outside the margin**, treated as a hyperparameter.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Cost Function for SVR\n",
    "\n",
    "The SVR cost function with hyperparameters is:\n",
    "\n",
    "$$\n",
    "\\min_{w, b, \\eta} \\frac{1}{2} \\| w \\|^2 + C \\sum_{i=1}^{n} \\eta_i\n",
    "$$\n",
    "\n",
    "**Where:**  \n",
    "- $$ w $$ → Weight vector  \n",
    "- $$ b $$ → Bias  \n",
    "- $$ \\eta_i $$ → Deviation from the margin  \n",
    "- $$ C $$ → Hyperparameter controlling trade-off between flatness of the line and penalty for errors  \n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Minimize $$ \\| w \\|^2 $$:** Keep the line as flat as possible.  \n",
    "2. **Minimize $$ \\sum \\eta_i $$:** Reduce the total deviation of points outside the margin.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Epsilon (ε) Tube\n",
    "\n",
    "- $$ \\epsilon $$ defines the **margin of tolerance**.  \n",
    "- Points **inside the ε-tube**: No penalty  \n",
    "- Points **outside the ε-tube**: Penalized using $$ \\eta_i $$  \n",
    "\n",
    "> Both $$ \\epsilon $$ and $$ \\eta_i $$ are **hyperparameters** that can be tuned.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Hyperparameters in SVR\n",
    "\n",
    "1. **$$ \\epsilon $$ (epsilon):** Maximum allowed error inside the margin.  \n",
    "2. **$$ \\eta_i $$:** Deviation of points outside the margin.  \n",
    "3. **$$ C $$:** Regularization hyperparameter controlling **penalty for deviations**.\n",
    "\n",
    "### Relationship between C and Loss:\n",
    "\n",
    "- As $$ C $$ **increases**, the **loss decreases**.  \n",
    "- This is because higher $$ C $$ penalizes deviations more, forcing the model to fit points more closely.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Summary of SVR Concept\n",
    "\n",
    "- SVR finds a **best-fit line** with **marginal planes**.  \n",
    "- Most points should lie **within the ε-tube**.  \n",
    "- Points outside the tube are handled with **deviation variables $$ \\eta_i $$**.  \n",
    "- **Cost function** balances **flatness** and **penalty for deviations**.  \n",
    "- Hyperparameters $$ \\epsilon $$, $$ \\eta_i $$, and $$ C $$ control model flexibility and tolerance.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Key Points to Remember\n",
    "\n",
    "1. SVR is used for **continuous output regression problems**.  \n",
    "2. The **best-fit line**: $$ w^T x + b $$  \n",
    "3. **Top margin**: $$ w^T x + b + \\epsilon $$  \n",
    "4. **Bottom margin**: $$ w^T x + b - \\epsilon $$  \n",
    "5. **Deviation outside margins**: $$ \\eta_i $$  \n",
    "6. **Hyperparameter C** controls penalty on deviations.  \n",
    "7. **Epsilon** defines the width of the margin tube.\n",
    "\n",
    "---\n",
    "\n",
    "> By adjusting $$ \\epsilon $$, $$ \\eta_i $$, and $$ C $$, SVR can handle **overlapping or noisy data**, making it robust for regression tasks.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce29ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
