{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5acf303",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Kernels – Complete Notes\n",
    "\n",
    "In this video, we are going to discuss **Support Vector Machine (SVM) Kernels**.\n",
    "\n",
    "Previously, we have learned about:\n",
    "\n",
    "- Support Vector Classifier (SVC)  \n",
    "- Support Vector Regressor (SVR)  \n",
    "- Hinge loss  \n",
    "- Best-fit line and marginal planes  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Linear SVC Recap\n",
    "\n",
    "The main goal of SVM is to:\n",
    "\n",
    "1. Find a **best-fit line**  \n",
    "2. Find **marginal planes**  \n",
    "\n",
    "For a **binary classification problem**, we use **SVC**.  \n",
    "When the decision boundary is a straight line, it is called **Linear SVC**.\n",
    "\n",
    "- Linear SVC creates a **straight line** as the decision boundary  \n",
    "- Along with **marginal planes**  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Problem with Non-Linearly Separable Data\n",
    "\n",
    "Consider data points in **2D** with features \\(x_1, x_2\\):\n",
    "\n",
    "- If points are **overlapping**, Linear SVC will fail.  \n",
    "- Accuracy will be low because the points are **not linearly separable**.  \n",
    "- Error will be high as many points cannot be correctly classified.  \n",
    "\n",
    "> Linear SVC works well only when the data is linearly separable.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Introduction to SVM Kernels\n",
    "\n",
    "When data is **not linearly separable**, we use **SVM Kernels**.\n",
    "\n",
    "- Kernels apply a **mathematical transformation** to the dataset.  \n",
    "- Transform data from a lower dimension (2D) to a **higher dimension (3D or more)**.  \n",
    "\n",
    "### Example:\n",
    "\n",
    "- Original data in 2D: overlapping points  \n",
    "- Apply transformation → data becomes separable in **3D**  \n",
    "- Linear SVC can now create a **3D hyperplane** and marginal planes  \n",
    "- Accuracy increases significantly\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Concept of Transformation\n",
    "\n",
    "- Transformation creates a **new axis** (e.g., \\(Z\\))  \n",
    "- Data points that were overlapping in 2D become **separable** in higher dimensions  \n",
    "- Example transformation:  \n",
    "\n",
    "  $$\n",
    "  y = x^2\n",
    "  $$\n",
    "\n",
    "- One-dimensional points can be converted into **2D** using this formula  \n",
    "- This allows **Linear SVC** to classify points correctly  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Example: 1D to 2D Transformation\n",
    "\n",
    "1. Initial 1D data points on \\(x\\)-axis:  \n",
    "\n",
    "   - Yellow points  \n",
    "   - Orange points  \n",
    "\n",
    "2. Apply transformation:  \n",
    "\n",
    "   $$\n",
    "   y = x^2\n",
    "   $$\n",
    "\n",
    "3. New 2D coordinates \\((x, y)\\)  \n",
    "\n",
    "4. Now points are **linearly separable**  \n",
    "\n",
    "5. Linear SVC can create:\n",
    "\n",
    "   - **Best-fit line**  \n",
    "   - **Marginal planes**  \n",
    "\n",
    "6. Result: Higher accuracy and correct classification  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Key Idea of SVM Kernels\n",
    "\n",
    "- Kernels **transform data into higher dimensions**  \n",
    "- Transformation formulas differ depending on the kernel type  \n",
    "- Goal: Make **non-linearly separable data** separable  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Types of SVM Kernels\n",
    "\n",
    "1. **Polynomial Kernel**  \n",
    "   - Applies polynomial transformation to create higher dimensions  \n",
    "\n",
    "2. **RBF (Radial Basis Function) Kernel**  \n",
    "   - Maps points into infinite-dimensional space using Gaussian function  \n",
    "\n",
    "3. **Sigmoid Kernel**  \n",
    "   - Uses the sigmoid function to transform data  \n",
    "\n",
    "> The key point: Kernels allow us to **create a higher-dimensional space** for better separation.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Summary\n",
    "\n",
    "- Linear SVC fails for **non-linearly separable data**  \n",
    "- **SVM Kernels** transform data into **higher dimensions**  \n",
    "- Transformation makes data **linearly separable** in the new space  \n",
    "- Linear SVC can now create **hyperplanes and marginal planes**  \n",
    "- Kernels are widely used in **interviews** and are **powerful in practice**\n",
    "\n",
    "---\n",
    "\n",
    "> Understanding SVM kernels is essential to handle **complex datasets** that are not linearly separable in their original feature space.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc532bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
